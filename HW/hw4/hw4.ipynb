{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Question 1. (20 points)\n",
    "1) Calculate by hand the empirical variance for the following datasets:\n",
    "(a) [4, 7, 9, 11, 15]\n",
    "(b) [18, 22, 25, 30, 35, 40]\n",
    "2) Once you have manually calculated the variance, confirm your result with Numpy.\n",
    "• Note that the documentation for numpy variance is at:\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.var.html\n",
    "• Read carefully the ddof option it determines if you are using empirical or population variance.\n",
    "3) Calculate the population variance for the following datasets:\n",
    "(a) [12, 14, 16, 18, 20]\n",
    "(b) [28, 32, 36, 40, 44, 48]\n",
    "4) Once you have manually calculated the population variance, confirm your result with Numpy.\n",
    "5) Comparing Variances\n",
    "(a) Explain the key differences between empirical and population variance calculations.\n",
    "(b) Provide an example where you should use population variance over empirical variance, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Variance Calculations:\n",
      "Dataset 1a: 17.2\n",
      "Dataset 1b: 68.26666666666668\n",
      "\n",
      "Population Variance Calculations:\n",
      "Dataset 3a: 8.0\n",
      "Dataset 3b: 46.666666666666664\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_1a = np.array([4, 7, 9, 11, 15])\n",
    "data_1b = np.array([18, 22, 25, 30, 35, 40])\n",
    "data_3a = np.array([12, 14, 16, 18, 20])\n",
    "data_3b = np.array([28, 32, 36, 40, 44, 48])\n",
    "\n",
    "print(\"Empirical Variance Calculations:\")\n",
    "print(\"Dataset 1a:\", np.var(data_1a, ddof=1))\n",
    "print(\"Dataset 1b:\", np.var(data_1b, ddof=1))\n",
    "\n",
    "print(\"\\nPopulation Variance Calculations:\")\n",
    "print(\"Dataset 3a:\", np.var(data_3a, ddof=0))\n",
    "print(\"Dataset 3b:\", np.var(data_3b, ddof=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "Question 3. (40 points) In the data folder, find and load the 2 files\n",
    "stock_prediction_data.csv\n",
    "stock_price.csv\n",
    "\n",
    "This data predicts tomorrow’s stock price difference given the previous day’s data.\n",
    "1) Split the data into Train, validation, test\n",
    "2) Preprocess the data, remove mean and scale it.\n",
    "3) Perform 2nd order polynomial regression with:\n",
    "(a) Lasso constraint\n",
    "(i) Solve it with your own gradient descent code\n",
    "(ii) Solve it with sklearn library (compare your results)\n",
    "(iii) Use the validation data to identify and ideal lambda value\n",
    "(b) Repeat the above steps with Ridge constraint\n",
    "(c) Repeat the above steps with Elastic net\n",
    "(d) How does Elastic Net compare with using only one constraint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Lasso Train MSE: 2.122974823830285\n",
      "Custom Lasso Validation MSE: 2.3665208202191628\n",
      "Scikit-learn Lasso Train MSE: 6.831045121140056\n",
      "Scikit-learn Lasso Validation MSE: 7.629002980184826\n",
      "Lasso Validation MSE: 0.08125352635324681 for lambda: 0.01\n",
      "Lasso Validation MSE: 0.09554581350427213 for lambda: 0.1\n",
      "Lasso Validation MSE: 2.3665208202191628 for lambda: 1\n",
      "Lasso Validation MSE: 46.70576127094301 for lambda: 10\n",
      "Optimal lambda for Lasso: 0.01 with MSE: 0.08125352635324681\n",
      "Custom Ridge Train MSE: 12.63957670786306\n",
      "Custom Ridge Validation MSE: 16.01545282823887\n",
      "Scikit-learn Ridge Train MSE: 0.03284528040883185\n",
      "Scikit-learn Ridge Validation MSE: 0.1038999941733034\n",
      "Ridge Validation MSE: 0.13532333433232058 for lambda: 0.01\n",
      "Ridge Validation MSE: 1.1402329224528376 for lambda: 0.1\n",
      "Ridge Validation MSE: 16.01545282823887 for lambda: 1\n",
      "Ridge Validation MSE: 42.66613532773383 for lambda: 10\n",
      "Optimal lambda for Ridge: 0.01 with MSE: 0.13532333433232058\n",
      "Scikit-learn Elastic Net Train MSE: 10.594131117049217\n",
      "Scikit-learn Elastic Net Validation MSE: 10.82774649966611\n",
      "Elastic Net Validation MSE: 0.12002440589744118 for l1_ratio: 0.1, lambda: 0.01\n",
      "Elastic Net Validation MSE: 0.7541926164690343 for l1_ratio: 0.1, lambda: 0.1\n",
      "Elastic Net Validation MSE: 14.567631683855423 for l1_ratio: 0.1, lambda: 1\n",
      "Elastic Net Validation MSE: 41.98442565423818 for l1_ratio: 0.1, lambda: 10\n",
      "Elastic Net Validation MSE: 0.7015409038195374 for l1_ratio: 0.5, lambda: 0.01\n",
      "Elastic Net Validation MSE: 1.1384011841205672 for l1_ratio: 0.5, lambda: 0.1\n",
      "Elastic Net Validation MSE: 8.381011322679042 for l1_ratio: 0.5, lambda: 1\n",
      "Elastic Net Validation MSE: 37.15354185532753 for l1_ratio: 0.5, lambda: 10\n",
      "Elastic Net Validation MSE: 1.894909119816642 for l1_ratio: 0.9, lambda: 0.01\n",
      "Elastic Net Validation MSE: 2.0148178179241816 for l1_ratio: 0.9, lambda: 0.1\n",
      "Elastic Net Validation MSE: 3.2943917565531864 for l1_ratio: 0.9, lambda: 1\n",
      "Elastic Net Validation MSE: 17.535633233606347 for l1_ratio: 0.9, lambda: 10\n",
      "Best Elastic Net l1_ratio: 0.1, lambda: 0.01 with MSE: 0.12002440589744118\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso as MyLasso, Ridge as MyRidge, ElasticNet as MyElasticNet\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load the data from CSV files\n",
    "X = np.genfromtxt('/Users/shreyas/Desktop/ML/HW/hw4/stock_prediction_data.csv', delimiter=',')\n",
    "y = np.genfromtxt('/Users/shreyas/Desktop/ML/HW/hw4/stock_price.csv', delimiter=',')\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "# Step 1: Split data into training, validation, and test sets\n",
    "X_train, X_remain, y_train, y_remain = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_remain, y_remain, test_size=0.5, random_state=42)\n",
    "\n",
    "# Step 2: Apply scaling to the features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 3: Transform the data into second-order polynomial features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=True)\n",
    "X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "X_val_poly = poly.transform(X_val_scaled)\n",
    "X_test_poly = poly.transform(X_test_scaled)\n",
    "\n",
    "# Custom gradient descent function for Lasso regression\n",
    "def lasso_grad_desc(X, y, lambda_val, learning_rate=0.01, max_iter=10000):\n",
    "    n, m = X.shape\n",
    "    weights = np.zeros((m, 1))\n",
    "    for i in range(max_iter):\n",
    "        y_pred = X @ weights\n",
    "        gradient = (2/n) * X.T @ (y_pred - y) + lambda_val * np.sign(weights)\n",
    "        \n",
    "        if np.all(np.abs(gradient) < 1e-5):\n",
    "            break\n",
    "        \n",
    "        weights -= learning_rate * gradient\n",
    "    return weights\n",
    "\n",
    "# Prediction function\n",
    "def predict_lasso(X, weights):\n",
    "    return X @ weights\n",
    "\n",
    "# Mean squared error (MSE) calculation\n",
    "def mse(y, y_pred):\n",
    "    return np.mean((y - y_pred) ** 2)\n",
    "\n",
    "# Custom Lasso regression training and validation\n",
    "weights_custom_lasso = lasso_grad_desc(X_train_poly, y_train, lambda_val=1)\n",
    "pred_train_custom_lasso = predict_lasso(X_train_poly, weights_custom_lasso)\n",
    "print(f\"Custom Lasso Train MSE: {mse(y_train, pred_train_custom_lasso)}\")\n",
    "pred_val_custom_lasso = predict_lasso(X_val_poly, weights_custom_lasso)\n",
    "print(f\"Custom Lasso Validation MSE: {mse(y_val, pred_val_custom_lasso)}\")\n",
    "\n",
    "# Lasso using scikit-learn\n",
    "lasso_model = MyLasso(alpha=1)\n",
    "lasso_model.fit(X_train_poly, y_train.flatten())\n",
    "pred_train_lasso_sklearn = lasso_model.predict(X_train_poly).reshape(-1, 1)\n",
    "print(f\"Scikit-learn Lasso Train MSE: {mse(y_train, pred_train_lasso_sklearn)}\")\n",
    "pred_val_lasso_sklearn = lasso_model.predict(X_val_poly).reshape(-1, 1)\n",
    "print(f\"Scikit-learn Lasso Validation MSE: {mse(y_val, pred_val_lasso_sklearn)}\")\n",
    "\n",
    "# Finding the best lambda for Lasso\n",
    "lambda_candidates = [0.01, 0.1, 1, 10]\n",
    "best_lambda = None\n",
    "best_mse_lasso = float('inf')\n",
    "\n",
    "for lambda_val in lambda_candidates:\n",
    "    weights = lasso_grad_desc(X_train_poly, y_train, lambda_val)\n",
    "    pred_val = predict_lasso(X_val_poly, weights)\n",
    "    current_mse = mse(y_val, pred_val)\n",
    "    print(f\"Lasso Validation MSE: {current_mse} for lambda: {lambda_val}\")\n",
    "    \n",
    "    if current_mse < best_mse_lasso:\n",
    "        best_mse_lasso = current_mse\n",
    "        best_lambda = lambda_val\n",
    "\n",
    "print(f\"Optimal lambda for Lasso: {best_lambda} with MSE: {best_mse_lasso}\")\n",
    "\n",
    "# Custom Ridge gradient descent\n",
    "def ridge_grad_desc(X, y, lambda_val, learning_rate=0.01, max_iter=10000):\n",
    "    n, m = X.shape\n",
    "    weights = np.zeros((m, 1))\n",
    "    for i in range(max_iter):\n",
    "        y_pred = X @ weights\n",
    "        gradient = (2/n) * X.T @ (y_pred - y) + 2 * lambda_val * weights\n",
    "        \n",
    "        if np.all(np.abs(gradient) < 1e-5):\n",
    "            break\n",
    "        \n",
    "        weights -= learning_rate * gradient\n",
    "    return weights\n",
    "\n",
    "# Custom Ridge training and validation\n",
    "weights_custom_ridge = ridge_grad_desc(X_train_poly, y_train, lambda_val=1)\n",
    "pred_train_custom_ridge = predict_lasso(X_train_poly, weights_custom_ridge)\n",
    "print(f\"Custom Ridge Train MSE: {mse(y_train, pred_train_custom_ridge)}\")\n",
    "pred_val_custom_ridge = predict_lasso(X_val_poly, weights_custom_ridge)\n",
    "print(f\"Custom Ridge Validation MSE: {mse(y_val, pred_val_custom_ridge)}\")\n",
    "\n",
    "# Ridge using scikit-learn\n",
    "ridge_model = MyRidge(alpha=1)\n",
    "ridge_model.fit(X_train_poly, y_train.flatten())\n",
    "pred_train_ridge_sklearn = ridge_model.predict(X_train_poly).reshape(-1, 1)\n",
    "print(f\"Scikit-learn Ridge Train MSE: {mse(y_train, pred_train_ridge_sklearn)}\")\n",
    "pred_val_ridge_sklearn = ridge_model.predict(X_val_poly).reshape(-1, 1)\n",
    "print(f\"Scikit-learn Ridge Validation MSE: {mse(y_val, pred_val_ridge_sklearn)}\")\n",
    "\n",
    "# Finding the best lambda for Ridge\n",
    "best_lambda_ridge = None\n",
    "best_mse_ridge = float('inf')\n",
    "\n",
    "for lambda_val in lambda_candidates:\n",
    "    weights = ridge_grad_desc(X_train_poly, y_train, lambda_val)\n",
    "    pred_val = predict_lasso(X_val_poly, weights)\n",
    "    current_mse = mse(y_val, pred_val)\n",
    "    print(f\"Ridge Validation MSE: {current_mse} for lambda: {lambda_val}\")\n",
    "    \n",
    "    if current_mse < best_mse_ridge:\n",
    "        best_mse_ridge = current_mse\n",
    "        best_lambda_ridge = lambda_val\n",
    "\n",
    "print(f\"Optimal lambda for Ridge: {best_lambda_ridge} with MSE: {best_mse_ridge}\")\n",
    "\n",
    "# Elastic Net with gradient descent\n",
    "def elastic_net_grad_desc(X, y, l1_ratio, lambda_val, learning_rate=0.01, max_iter=10000):\n",
    "    n, m = X.shape\n",
    "    weights = np.zeros((m, 1))\n",
    "    for i in range(max_iter):\n",
    "        y_pred = X @ weights\n",
    "        gradient = (2/n) * X.T @ (y_pred - y) + l1_ratio * np.sign(weights) + (1 - l1_ratio) * 2 * lambda_val * weights\n",
    "        \n",
    "        if np.all(np.abs(gradient) < 1e-5):\n",
    "            break\n",
    "        \n",
    "        weights -= learning_rate * gradient\n",
    "    return weights\n",
    "\n",
    "# Elastic Net using scikit-learn\n",
    "elastic_net_model = MyElasticNet(alpha=1, l1_ratio=0.5)\n",
    "elastic_net_model.fit(X_train_poly, y_train.flatten())\n",
    "pred_train_elastic_net_sklearn = elastic_net_model.predict(X_train_poly).reshape(-1, 1)\n",
    "print(f\"Scikit-learn Elastic Net Train MSE: {mse(y_train, pred_train_elastic_net_sklearn)}\")\n",
    "pred_val_elastic_net_sklearn = elastic_net_model.predict(X_val_poly).reshape(-1, 1)\n",
    "print(f\"Scikit-learn Elastic Net Validation MSE: {mse(y_val, pred_val_elastic_net_sklearn)}\")\n",
    "\n",
    "# Finding best hyperparameters for Elastic Net\n",
    "l1_ratios = [0.1, 0.5, 0.9]\n",
    "best_mse_elastic_net = float('inf')\n",
    "best_l1_ratio = None\n",
    "best_lambda_elastic_net = None\n",
    "\n",
    "for l1_ratio in l1_ratios:\n",
    "    for lambda_val in lambda_candidates:\n",
    "        weights = elastic_net_grad_desc(X_train_poly, y_train, l1_ratio, lambda_val)\n",
    "        pred_val = predict_lasso(X_val_poly, weights)\n",
    "        current_mse = mse(y_val, pred_val)\n",
    "        print(f\"Elastic Net Validation MSE: {current_mse} for l1_ratio: {l1_ratio}, lambda: {lambda_val}\")\n",
    "        \n",
    "        if current_mse < best_mse_elastic_net:\n",
    "            best_mse_elastic_net = current_mse\n",
    "            best_l1_ratio = l1_ratio\n",
    "            best_lambda_elastic_net = lambda_val\n",
    "\n",
    "print(f\"Best Elastic Net l1_ratio: {best_l1_ratio}, lambda: {best_lambda_elastic_net} with MSE: {best_mse_elastic_net}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve it with sklearn library (compare your results)\n",
    "\n",
    "The custom Lasso implementation outperformed the scikit-learn version, with lower MSEs (2.12 train, 2.37 validation) compared to scikit-learn's (6.83 train, 7.63 validation). The optimal lambda for Lasso was 0.01, giving a validation MSE of 0.08. Ridge performed best overall with scikit-learn, achieving a train MSE of 0.03 and validation MSE of 0.10. Elastic Net, with an optimal l1_ratio of 0.1 and lambda of 0.01, had a validation MSE of 0.12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does Elastic Net compare with using only one constraint?\n",
    "\n",
    "Elastic Net, which combines both Lasso and Ridge penalties, performed better than Lasso but slightly worse than Ridge. Its optimal validation MSE was 0.12, compared to Ridge’s 0.10 and Lasso’s 0.08. Elastic Net provides a balance between the two constraints but did not outperform Ridge in this case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
