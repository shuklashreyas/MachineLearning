{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Question 1. (20 points)\n",
    "1) Calculate by hand the empirical variance for the following datasets:\n",
    "(a) [4, 7, 9, 11, 15]\n",
    "(b) [18, 22, 25, 30, 35, 40]\n",
    "2) Once you have manually calculated the variance, confirm your result with Numpy.\n",
    "• Note that the documentation for numpy variance is at:\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.var.html\n",
    "• Read carefully the ddof option it determines if you are using empirical or population variance.\n",
    "3) Calculate the population variance for the following datasets:\n",
    "(a) [12, 14, 16, 18, 20]\n",
    "(b) [28, 32, 36, 40, 44, 48]\n",
    "4) Once you have manually calculated the population variance, confirm your result with Numpy.\n",
    "5) Comparing Variances\n",
    "(a) Explain the key differences between empirical and population variance calculations.\n",
    "(b) Provide an example where you should use population variance over empirical variance, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical Variance Calculations:\n",
      "Dataset 1a: 17.2\n",
      "Dataset 1b: 68.26666666666668\n",
      "\n",
      "Population Variance Calculations:\n",
      "Dataset 3a: 8.0\n",
      "Dataset 3b: 46.666666666666664\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_1a = np.array([4, 7, 9, 11, 15])\n",
    "data_1b = np.array([18, 22, 25, 30, 35, 40])\n",
    "data_3a = np.array([12, 14, 16, 18, 20])\n",
    "data_3b = np.array([28, 32, 36, 40, 44, 48])\n",
    "\n",
    "print(\"Empirical Variance Calculations:\")\n",
    "print(\"Dataset 1a:\", np.var(data_1a, ddof=1))\n",
    "print(\"Dataset 1b:\", np.var(data_1b, ddof=1))\n",
    "\n",
    "print(\"\\nPopulation Variance Calculations:\")\n",
    "print(\"Dataset 3a:\", np.var(data_3a, ddof=0))\n",
    "print(\"Dataset 3b:\", np.var(data_3b, ddof=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "Question 3. (40 points) In the data folder, find and load the 2 files\n",
    "stock_prediction_data.csv\n",
    "stock_price.csv\n",
    "\n",
    "This data predicts tomorrow’s stock price difference given the previous day’s data.\n",
    "1) Split the data into Train, validation, test\n",
    "2) Preprocess the data, remove mean and scale it.\n",
    "3) Perform 2nd order polynomial regression with:\n",
    "(a) Lasso constraint\n",
    "(i) Solve it with your own gradient descent code\n",
    "(ii) Solve it with sklearn library (compare your results)\n",
    "(iii) Use the validation data to identify and ideal lambda value\n",
    "(b) Repeat the above steps with Ridge constraint\n",
    "(c) Repeat the above steps with Elastic net\n",
    "(d) How does Elastic Net compare with using only one constraint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso (sklearn) Validation MSE: 6.964057757126562\n",
      "Lasso (custom) Validation MSE: 7.783251445060104\n",
      "Ridge (sklearn) Validation MSE: 0.07902035873867781\n",
      "Elastic Net (sklearn) Validation MSE: 11.630834838017531\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "\n",
    "stock_prediction_data = pd.read_csv('/Users/shreyas/Desktop/ML/HW/hw4/stock_prediction_data.csv')\n",
    "stock_price = pd.read_csv('/Users/shreyas/Desktop/ML/HW/hw4/stock_price.csv')\n",
    "\n",
    "X = stock_prediction_data.values\n",
    "y = stock_price.values\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "X_val_poly = poly.transform(X_val_scaled)\n",
    "X_test_poly = poly.transform(X_test_scaled)\n",
    "\n",
    "lasso_model_sklearn = Lasso(alpha=1.0, max_iter=10000)\n",
    "lasso_model_sklearn.fit(X_train_poly, y_train.ravel())\n",
    "y_val_pred_sklearn_lasso = lasso_model_sklearn.predict(X_val_poly)\n",
    "mse_val_sklearn_lasso = np.mean((y_val_pred_sklearn_lasso - y_val.ravel()) ** 2)\n",
    "\n",
    "def lasso_gradient_descent(X, y, alpha, learning_rate=0.001, max_iter=10000):\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros(n)\n",
    "    for _ in range(max_iter):\n",
    "        y_pred = X @ theta\n",
    "        gradient = (1/m) * (X.T @ (y_pred - y)) + alpha * np.sign(theta)\n",
    "        theta -= learning_rate * gradient\n",
    "    return theta\n",
    "\n",
    "theta_custom_lasso = lasso_gradient_descent(X_train_poly, y_train.ravel(), alpha=1.0)\n",
    "y_val_pred_custom_lasso = X_val_poly @ theta_custom_lasso\n",
    "mse_val_custom_lasso = np.mean((y_val_pred_custom_lasso - y_val.ravel()) ** 2)\n",
    "\n",
    "ridge_model_sklearn = Ridge(alpha=1.0, max_iter=10000)\n",
    "ridge_model_sklearn.fit(X_train_poly, y_train.ravel())\n",
    "y_val_pred_sklearn_ridge = ridge_model_sklearn.predict(X_val_poly)\n",
    "mse_val_sklearn_ridge = np.mean((y_val_pred_sklearn_ridge - y_val.ravel()) ** 2)\n",
    "\n",
    "elastic_net_model_sklearn = ElasticNet(alpha=1.0, l1_ratio=0.5, max_iter=10000)\n",
    "elastic_net_model_sklearn.fit(X_train_poly, y_train.ravel())\n",
    "y_val_pred_sklearn_elastic = elastic_net_model_sklearn.predict(X_val_poly)\n",
    "mse_val_sklearn_elastic = np.mean((y_val_pred_sklearn_elastic - y_val.ravel()) ** 2)\n",
    "\n",
    "print(f'Lasso (sklearn) Validation MSE: {mse_val_sklearn_lasso}')\n",
    "print(f'Lasso (custom) Validation MSE: {mse_val_custom_lasso}')\n",
    "print(f'Ridge (sklearn) Validation MSE: {mse_val_sklearn_ridge}')\n",
    "print(f'Elastic Net (sklearn) Validation MSE: {mse_val_sklearn_elastic}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve it with sklearn library (compare your results)\n",
    "\n",
    "Using sklearn, Lasso resulted in a validation MSE of 6.96, Ridge performed best with 0.079, and Elastic Net had the highest MSE at 11.63. Ridge outperformed both Lasso and Elastic Net, indicating that its penalty (shrinking coefficients but keeping all features) worked best for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does Elastic Net compare with using only one constraint?\n",
    "\n",
    "Elastic Net, combining Lasso and Ridge, performed worse than either method alone, with an MSE of 11.63. Ridge, which had the lowest MSE (0.079), was more effective than Elastic Net, suggesting that a single Ridge constraint worked better for this data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
